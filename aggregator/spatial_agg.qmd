---
title: "Spatial aggregation"
author: "Galen Holt"
format:
  html:
    df-print: paged
editor: visual
---

```{r}
library(werptoolkitr)
library(dplyr)
library(ggplot2)
library(patchwork)
```

## Overview

We will often have spatial data that we want to aggregate into larger scales. We therefore want a set of functions that allow us to read in data, specify the larger units into which it gets aggregated and the functions to use to do that aggregation. Further, there is clear need to handle grouping, most obviously for scenarios, but we also need to keep theme groupings separated during spatial aggregation steps.

There is a standalone spatial aggregator `spatial_aggregate`, which I demonstrate here, along with `multi_aggregate`, which wraps both `spatial_aggregate` and `theme_aggregate` to allow interleaved aggregaton steps in a standardised format. This document focuses on spatial aggregation, while [theme aggregation](theme_agg.qmd) and [interleaved spatial and theme aggregation](theme_space_agg.qmd) are demonstrated in separate notebooks, allowing us to dig a little deeper into how each component works.

We often will want to only perform a single spatial aggregation (e.g. from gauges to sdl units), but there are instances where that isn't true- perhaps we want to aggregate from sdl units to states or the basin. Thus, I demonstrate multi-step spatial aggregation, including the situation where aggregation units (polygons) are not nested, as would be the case for sdl units and states, for example. Even if some of the steps in this demonstration aren't particularly interesting now, they allow us to develop the general process that can accept any set of polygons we want to aggregate into from any other spatial data.

This document delves fairly in-depth into *capabilities*, including things like argument types and how they relate to other functions and permit certain tricks. Not all of these will be used or needed to understand by most users- typically there will be a set of aggregation steps fed to `multi_aggregate` and that will be that. This sort of simpler setup is shown in the [combined aggregation notebook](theme_space_agg.qmd) and the [full-toolkit runs](full_toolkit/full_toolkit_overview.qmd). But it is helpful to document them for when they are needed.

## Inputs

We will need to be able to accept inputs at arbitrary aggregation levels (theme, spatial, or temporal). In other words, the spatial aggregation should aggregate any input spatial data into any set of spatial units, whatever that input data represents. The `multi_aggregate` function runs without spatial info until it reaches a step calling for spatial aggregation, at which point that data must be spatial. Beyond this requirement, `multi_aggregate` doesn't care what theme or spatial scale that input data is- e.g. we could give it Objectives already at the Catchment scale, and then use it to move up.

::: {#spatial-themes style="border: 2px solid gray; color: gray"}
Note: in some cases, the definitions for outcomes along the 'Objective' axis are defined spatially; for example, the definition of `Specific_objectives` might vary between planning units. However, these are the scale at which *definitions* of outcomes change, not the scale at which those outcomes must be assessed. For example, just because `Specific_objectives` are differently defined between planning units, we can still scale them up in space from gauge to basin, with no reference to planning unit.
:::

For this demonstration, we start with gauge-referenced data at the `env_obj` theme scale.

## Demonstration setup

First, we need to provide a set of paths to point to the input data, in this case the outputs from the EWR tool for the small demonstration, created by [a controller notebook](controller/controller_ewr_wrapped_R.qmd). Spatial units could be any arbitrary polygons, but we use those provided by [{werptoolkitr}](https://github.com/MDBAuth/WERP_toolkit) for consistency, which also provides the spatial locations of the gauges in `bom_basin_gauges`.

```{r}
project_dir <- file.path('scenario_example')
ewr_results <- file.path(project_dir, 'module_output', 'EWR')
```

### Theme aggregated inputs

The `multi_aggregate` function can combine theme and spatial aggregation, but because I want this document to demonstrate spatial aggregation, I have split up the process to be clear what is happening. First, we do a theme aggregation to get to the desired Theme level to feed to spatial.

Before any aggregation, we need to read the data in and make it spatial (`gauge2geo` pairs gauge numbers with locations provided in the `geopath` argument inside `prep_ewr_agg`. Note that this prep step is wrapped in `read_and_agg`, reducing user input. I show it here so we can more clearly see what is happening.

```{r}
#| message: false
sumdat <- prep_ewr_agg(ewr_results, type = 'summary', geopath = bom_basin_gauges)
```

Define simple theme aggregation lists to get to `env_obj` level, assuming that any pass on `ewr_code_timing` yields a pass for `ewr_code` and `ewr_code`s are averaged into `env_obj`. More complexity for the theme aggregations are shown [in the theme notebook](theme_agg.qmd).

```{r}
themeseq <- list(c('ewr_code_timing', 'ewr_code'),
               c('ewr_code', "env_obj"))

funseq <- list(c('CompensatingFactor'),
               c('ArithmeticMean'))
```

Perform that simple theme aggregation so we have some test data. Since edges are only relevant for theme aggregation, make them in the call. This and everything that follows could be done with interleaved theme and spatial sequences starting with `themeseq` and `funseq` fed to `multi_aggregate`, but here I split them apart to better accentuate the spatial aggregation.

```{r}
#| message: false
#| warning: false


simpleThemeAgg <- multi_aggregate(dat = sumdat,
                         causal_edges = make_edges(causal_ewr, themeseq),
                         groupers = c('scenario', 'gauge'),
                         aggCols = 'ewr_achieved',
                         aggsequence = themeseq,
                         funsequence = funseq)
simpleThemeAgg
```

This provides a spatially-referenced (to gauge) theme-aggregated tibble to use to demonstrate spatial aggregation. Note that this has the gauge (spatial unit), but also two groupings that we want to preserve when we spatially aggregate- `scenario` and the current level of theme grouping, `env_obj`.

### Spatial inputs (polygons)

Spatial aggregation requires polygons to aggregate into, and we want the capability to do that several times. The user can read in any desired polygons with `sf::read_sf(path/to/polygon.shp)`, but here we use those provided in the standard set with {werptoolkitr}. We'll use SDL units, catchments (from cewo), and the basin to show how the aggregation can have multiple steps with polygons that may not be nested (though care should be taken when that is the case).

# Demonstrations

We'll now use that input data to demonstrate how to do the spatial aggregation, demonstrate capabilities and options provided by the function, and provide additional information useful to the user.

## Single aggregation

We might just want to aggregate spatially once. We can do this simply by passing the input data (anything spatial, in this case `simpleThemeAgg`), a set of polygons, and providing a length-one `funlist`.

Note that the `aggCols` argument is `ends_with(original_name)` to reference the *original* name of the column of values- it may have a [long name tracking its aggregation history](aggregation_overview.qmd), so we give it the tidyselect `ends_with` to find the column. More generally, both `aggCols` and `groupers` can take any tidyselect syntax or bare names or characters.

```{r}
#| message: false

obj2poly <- spatial_aggregate(dat = simpleThemeAgg, 
                             to_geo = sdl_units,
                             groupers = 'scenario',
                             aggCols = ends_with('ewr_achieved'),
                             funlist = ArithmeticMean,
                             keepAllPolys = TRUE)
obj2poly
```

Note that that has a horribly long name tracking the aggregation history, and has lost the theme levels- e.g. the different `env_obj`s are no longer there and were all averaged together. The `multi_aggregate` function automatically handles this preservation, but `spatial_aggregate` is more general, and does not make any assumptions about the grouping structure of the data. Thus, to keep the `env_obj` groupings (as we should, otherwise we're inadvertently theme-aggregating over all of them), we need to add `env_obj` to the `groupers` argument.

```{r}

obj2poly <- spatial_aggregate(dat = simpleThemeAgg, 
                             to_geo = sdl_units,
                             groupers = c('scenario', 'env_obj'),
                             aggCols = ends_with('ewr_achieved'),
                             funlist = ArithmeticMean,
                             keepAllPolys = TRUE)
obj2poly
```

A quick plot shows what we're dealing with. We'll simplify the names and choose a subset of the environmental objectives.

There are many built-in plotting options in the toolkit, which we will use shortly. First, though a quick ggplot to see what those standardised plot functions start with.

```{r}
# The name is horrible, so change it.
obj2poly %>% 
  rename(ewr_achieved = spatial_ArithmeticMean_env_obj_ArithmeticMean_ewr_code_CompensatingFactor_ewr_achieved) %>% 
  filter(grepl('^EF', env_obj)) %>% 
ggplot(aes(fill = ewr_achieved)) +
  geom_sf() + 
  facet_grid(scenario~env_obj)
```

Moving forward, we'll use the built-in plotting functions to keep consistent with the rest of the project.

```{r}
scene_pal <- make_pal(unique(simpleThemeAgg$scenario), palette = 'ggsci::nrc_npg', refvals = 'base', refcols = 'black')
```

```{r}
obj2poly %>% 
  rename(ewr_achieved = spatial_ArithmeticMean_env_obj_ArithmeticMean_ewr_code_CompensatingFactor_ewr_achieved) %>% 
  filter(grepl('^EF[1-3]', env_obj)) %>% 
plot_outcomes(y_col = 'ewr_achieved',
                  y_lab = 'Arithmetic Mean',
                          x_col = 'map',
                          colorgroups = NULL,
                          colorset = 'ewr_achieved',
                          pal_list = list('scico::berlin'),
                          facet_col = 'env_obj',
                          facet_row = 'scenario',
                          scene_pal = scene_pal,
                          sceneorder = c('down4', 'base', 'up4'),
                          underlay_list = list(underlay = basin, 
                                               underlay_pal = 'azure'))
```

### Argument options and syntax

Both `aggCols` and `groupers` can be character vectors, bare data-variable names, or we might want to use `tidyselect` syntax. For example, maybe we want to use `ends_with('ewr_achieved')` as above to grab pre-aggregated columns with long name histories, as in `simpleThemeAgg` . This is handled under the hood by `selectcreator` and careful parsing in the function stack. Above, we had groupers as a character vector and aggCols as tidyselect, but now we flip, and `groupers` is a vector of tidyselect and bare names, while `aggCols` is a character.

::: {#tidyselect style="border: 2px solid gray; color: gray"}
Note that `multi_aggregate` takes advantage of this tidyselect ability under the hood to deal with the ever-lengthening column names (and sometimes expanding number of value columns if we have multiple aggregation functions at a step).

Also, if we were doing all the aggregation in one go using `multi_aggregate`, we could avoid the super long names by just using `namehistory = FALSE`. We'll get to that in the [combined aggregation](theme_space.qmd).
:::

```{r}
obj2poly2 <- spatial_aggregate(dat = simpleThemeAgg, 
                             to_geo = sdl_units,
                             groupers = c(starts_with('sce'), env_obj),
                             aggCols = "env_obj_ArithmeticMean_ewr_code_CompensatingFactor_ewr_achieved",
                             funlist = ArithmeticMean,
                             keepAllPolys = TRUE)

obj2poly2
```

We can see we get the same result as `obj2poly` with different ways of specifying `aggCols` and `groupers`.

**STOPPED HERE 14/4/2023**

There are times when we might want to send a vector of names, but ignore those not in the data. Most likely would be something like grouping on `gauge` if it exists, and ignoring if not. It fails by default, but setting `failmissing = FALSE` allows it to pass. I want that to be in `…` to pass to `selectcreator`, but we're already using the `…` for function arguments and it gets tangled up.

```{r}
#| message: false

obj2polyF <- spatial_aggregate(dat = sumdat, 
                             to_geo = rps,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                             funlist = ArithmeticMean,
                             keepAllPolys = TRUE,
                             failmissing = FALSE)

ggplot(obj2polyF, aes(fill = spatial_ArithmeticMean_ewr_achieved)) +
  geom_sf() + 
  facet_grid(scenario~.)
```

### Functions

We can pass single bare aggregatoin function names, or characters. If we want to do two different aggregations on the same data, we can pass a vector.

```{r}
#| message: false
simplefuns <- list('ArithmeticMean', 'GeometricMean')

doublesimple <- spatial_aggregate(dat = sumdat, 
                             to_geo = rps,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                             funlist = simplefuns,
                             keepAllPolys = TRUE,
                             failmissing = FALSE)
```

Using the `~` syntax of functions in a named list, we can pass arguments to the functions.

```{r}
#| message: false
simplelamfuns <- list(mean = ~mean(., na.rm = TRUE), 
                     sd = ~sd(., na.rm = TRUE))

doublelam <- spatial_aggregate(dat = sumdat, 
                             to_geo = rps,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                             funlist = simplelamfuns,
                             keepAllPolys = TRUE,
                             failmissing = FALSE)
```

It's fairly common that we'll have vector arguments for the spatial aggregations, for example weightings. I have fairly complex code elsewhere (and previously here) to pass in vectors separate from the data and/or create them internally. There is *much* more flexibility in how we specify functions though if we just insist they are attached to the data before it enters the function. Here, demonstrate with weighted means on dummy weights.

```{r}
#| message: false
veclamfuns <- list(mean = ~mean(., na.rm = TRUE), 
                     sd = ~sd(., na.rm = TRUE),
                     wm = ~weighted.mean(., wt, na.rm = TRUE))

# Not really meaningful, but weight by the number of gauges.
wtgauge <- sumdat %>% 
  dplyr::group_by(scenario, gauge) %>% 
  dplyr::mutate(wt = dplyr::n()) %>% 
  dplyr::ungroup()

triplevec <- spatial_aggregate(dat = wtgauge, 
                             to_geo = rps,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                             funlist = veclamfuns,
                             keepAllPolys = TRUE,
                             failmissing = FALSE)
```

Finally, if there is a single function, we can pass just one funlist and its arg, e.g. mean, na.rm = TRUE.

```{r}
#| message: false
singlearg <- spatial_aggregate(dat = wtgauge, 
                             to_geo = rps,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                 funlist = mean,
                 na.rm = TRUE,
                 keepAllPolys = TRUE,
                 failmissing = FALSE)
```

In summary, we can pass single functions and their args in ellipses, complex lists of multiple functions using tilde, which can have vector args (as long as the vector is attached to the data), and lists of multiple function names. The only thing I *can't* do is pass unattached vector args. I have to do such convoluted things for that to work with *one* function, and it's so easy to just bind them on, I think that's a tradeoff I'm willing to make. I guess we can reassess if this becomes an issue later.

The only exceptions to this are situations where the needed vector arguments have to depend on both sets of from and to data/polygons, and so can't be pre-attached. The main way this comes up is with area-weighting, so `spatial_joiner` calculates areas so there is always an `area` column available for weighting. If additional internal calculations are needed we'll have to make some larger changes.

## Multiple spatial levels

We've been operating on resource areas, now also use ltim valleys `ltv`. These are not nested (and not even necessarily smaller). As such, it makes a good test case that catches issues with the intersection of polygons that might not happen with a simpler set of polygons. Here, colored lines are catchments `ltv`, and fill colors are resource areas `rps`.zs

```{r}
ggplot() +
  geom_sf(data = ltv, aes(color = ValleyName), fill = 'white') +
  geom_sf(data = rps, aes(fill = SWWRPANAME), color = NA, alpha = 0.5) + 
  theme(legend.position = 'none')
```

That's surprisingly hard to read, let's just plot them next to each other

```{r}
valleys <- ggplot() +
  geom_sf(data = ltv, aes(color = ValleyName), fill = 'white') + 
  theme(legend.position = 'none')

resources <- ggplot() +
  geom_sf(data = rps, aes(fill = SWWRPANAME), alpha = 0.5) + 
  theme(legend.position = 'none')

valleys + resources
```

To aggregate from one into the other, we need to split them up and aggregate in a way that respects area or borders. In other words, if we have a polygon that lays across two of the next level up, we want to only include the bits that overlap into that next level up, and so we need `st_intersection`, which actually splits the polygons to make a new set of nonoverlapping polygons. Then we can use these pieces to aggregate into the higher-level. We still need to be careful- things like means should be area-weighted, and things like sums, minima, and maxima should be thought about carefully- area weighting can work, but needs to be done right, and so there may be custom functions involved.

The intersection of `rps` and `ltv` puts all the `rps` into valleys, and chopped them up as necessary.

```{r}
#| warning: false
#| message: false
joinpolys <- st_intersection(rps, ltv)
joinpolys
```

To better see the many-to-many chopping we get with this particular pair of intersecting shapefiles, we can isolate a resource area (Northern Victoria) and see that it contains bits of 8 catchments. Likewise, the Loddon catchment contains bits of two resource areas.

```{r}
nvorig <- ggplot() +
  geom_sf(data = dplyr::filter(rps, SWWRPANAME == "Northern Victoria"))

nvpostjoin <- ggplot() +
  geom_sf(data = dplyr::filter(joinpolys, 
                        SWWRPANAME == "Northern Victoria"), 
          aes(fill = ValleyName))

avorig <- ggplot() +
  geom_sf(data = dplyr::filter(ltv, ValleyName == 'Loddon'))

avpostjoin <- ggplot() +
  geom_sf(data = dplyr::filter(joinpolys, 
                        ValleyName == 'Loddon'), 
          aes(fill = SWWRPANAME))

(nvorig + nvpostjoin)/(avorig + avpostjoin)
```

### Aggregation into each poly set

Before we aggregate sequentially, let's aggregate into the other poly sets separately (catchment and basin).

```{r}
obj2ltv <- spatial_aggregate(dat = sumdat, 
                             to_geo = ltv,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                             funlist = ArithmeticMean,
                             keepAllPolys = TRUE)

ggplot(obj2ltv, aes(fill = spatial_ArithmeticMean_ewr_achieved)) +
  geom_sf() + 
  facet_grid(scenario~.)
```

```{r}
obj2basin <- spatial_aggregate(dat = sumdat, 
                             to_geo = basin,
                             groupers = 'scenario',
                             aggCols = 'ewr_achieved',
                             funlist = ArithmeticMean,
                             keepAllPolys = TRUE)

ggplot(obj2basin, aes(fill = spatial_ArithmeticMean_ewr_achieved)) +
  geom_sf() + 
  facet_grid(scenario~.)
```

## Test poly to poly

We can again do a one-off aggregation from a polygon to another polygon using `spatial_aggregate`. We have a bunch of aggregations into `rps` , use `obj2poly` as a demo.

```{r}
#| warning: false
#| message: false
simplepolypoly <- spatial_aggregate(dat = obj2poly, 
                 to_geo = ltv,
                 groupers = 'scenario',
                 aggCols = 'ewr_achieved',
                 funlist = mean,
                 na.rm = TRUE,
                 keepAllPolys = TRUE,
                 failmissing = FALSE)
simplepolypoly
```

## Passing a list

We can use `multi_aggregate` to aggregate through a list of polygon sets. I had a specialised function for just space, but have deprecated it in favour of `multi_aggregate`, since that allows interleaving with theme. For now, though, we're just demonstrating space.

First, set up a list of the spatial aggregation steps, defined by the polygon sets and aggregation functions. As usual, multiple aggregation functions can happen at each stage, and they can be characters or named lists with arguments (the weighted mean needs to be a default). Now, we're taking advantage of the auto-calculated area of each polygon chunk for the weighted mean.

```{r}
glist <- list(rps = rps, catchment = ltv, mdb = basin)

funlist <- list(c('ArithmeticMean', 'LimitingFactor'),
                list(wm = ~weighted.mean(., area, na.rm = TRUE)),
                list(wm = ~weighted.mean(., area, na.rm = TRUE)))
```

```{r}
#| warning: false
#| message: false
multispat <- multi_aggregate(dat = sumdat,
                         causal_edges = themeedges,
                         groupers = 'scenario',
                         aggCols = 'ewr_achieved',
                         aggsequence = glist,
                         funsequence = funlist)
```

That works, but it'll be easier to see with other options, and we want to demo some of those options.

```{r}
ggplot(multispat) +
  geom_sf(aes(fill = mdb_wm_catchment_wm_rps_ArithmeticMean_ewr_achieved)) +
  facet_grid('scenario')
```

### Saveintermediate and namehistory

We might only want the final outcome as above, but we also might want all the steps (just as we did for the theme). And making the history in columns keeps the names easier to use, even if it eats more memory.

```{r}
#| message: false
#| warning: false
multispatb <- multi_aggregate(dat = sumdat,
                         causal_edges = themeedges,
                         groupers = 'scenario',
                         aggCols = 'ewr_achieved',
                         aggsequence = glist,
                         funsequence = funlist,
                               saveintermediate = TRUE,
                               namehistory = FALSE)
```

Quick check- is that final list item scenario \* aggfun1\*aggfun2\*aggfun3 long?

```{r}
length(unique(multispatb$mdb$scenario)) * 
length(unique(multispatb$mdb$aggfun_1)) * 
length(unique(multispatb$mdb$aggfun_2)) * 
length(unique(multispatb$mdb$aggfun_3))

nrow(multispatb$mdb)
```

Now we can more easily analyse the output, but it's bigger. The three spatial levels plus the input can be mapped. This is crude- better maps in dev for comparer.

```{r}
l1 <- ggplot(multispatb$sumdat) + 
  geom_sf(data = basin) +
  geom_sf(aes(color =  ewr_achieved))

l2 <- ggplot(multispatb$rps) + 
  geom_sf(data = basin) +
  geom_sf(aes(fill =  ewr_achieved))

l3 <- ggplot(multispatb$catchment) + 
  geom_sf(data = basin) +
  geom_sf(aes(fill = ewr_achieved))

l4 <- ggplot(multispatb$mdb) + 
  geom_sf(data = basin) +
  geom_sf(aes(fill =  ewr_achieved))

l1 + l2 + l3 + l4 + plot_layout(ncol = 2)
```

Clearly need to make guides consistent, but that's later in plot development.

### failmissing and keepallpolys

As above, we might want to ignore some groupers or aggregation columns, and we might want to keep polygons that don't have data so the maps loop better.

```{r}
#| message: false
#| warning: false
multispatextra <- multi_aggregate(sumdat, 
                                    causal_edges = themeedges,
                               groupers = c('scenario', 'doesnotexist'), 
                               aggCols = c('ewr_achieved', 'notindata'),
                               aggsequence = glist,
                         funsequence = funlist,
                               saveintermediate = TRUE,
                               namehistory = FALSE,
                               failmissing = FALSE,
                               keepAllPolys = TRUE)
```

And if we plot the version from above and this one, they should have different polys. Let's go with the ltv?

The default is `keepAllPolys = FALSE`, so the original only has relevant catchments.

```{r}
keepfalse <- multispatb$catchment %>% 
  dplyr::filter(aggfun_1 == 'ArithmeticMean' & aggfun_2 == 'wm') %>% 
  ggplot() + geom_sf(aes(fill = ewr_achieved))

keeptrue <- multispatextra$catchment %>% 
  dplyr::filter(aggfun_1 == 'ArithmeticMean' & aggfun_2 == 'wm') %>% 
  ggplot() + geom_sf(aes(fill = ewr_achieved))

keepfalse + keeptrue
```

## Using multi for one

If we're only using one level of spatial aggregation, there's typically no need for the `multi_aggregate` wrapper. But if there is, we can use it. Replicating some of the earliest aggregations works. We do have a bit less flexibility with how we specify arguments- `aggsequence` and `funsequence` need to be lists or characters (`funsequence` cannot be bare function names). And `tidyselect` in aggCols runs into issues because it gets used again inside `multi_aggregate`, and so `tidyselect` here collides with that. That could all be sorted out, but seems low priority- easier to just enforce characters for `aggCols` and lists or characters for the sequences.

Typically we could use `namehistory = FALSE` to avoid the horrible long name with all the transforms in it, but there's no way for it to know the previous aggregation history when it's been done in pieces. Again, fixable, but low priority. Just do it all on one go, usually. If not, change the `labs` and call it good.

```{r}
#| message: false

obj2polyM1 <- multi_aggregate(simpleThemeAgg,
                            causal_edges = themeedges,
                            groupers = c('scenario', 'env_obj'), 
                         aggCols = 'ewr_achieved',
                         aggsequence = list(rps = rps),
                         funsequence = list(list(am = ~ArithmeticMean(.))),
                         keepAllPolys = TRUE)

# namehistory = FALSE doesn't have a way of knowing about previous aggregation, so not much point in using it.
ggplot(obj2polyM1, aes(fill = rps_am_env_obj_ArithmeticMean_ewr_code_CompensatingFactor_ewr_achieved)) +
  geom_sf() + 
  facet_grid(scenario~.) +
  labs(fill = 'ewr_achieved')
```

# TODO

-   testing

-   more flexible tidyselect and function arguments

-   default area-weighted functions

-   Develop plots in comparer

-   main aggregator todo in theme_space_agg.qmd
